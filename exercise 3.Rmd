---
title: "Exercise Sheet 3"
author: "Lea Kunze (12790172)"
date: "2025-05-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### **d) Name 2 strengths and 2 weaknesses of Git.**

**Strengths:**

1.  **Version Control:** Git allows you to track changes over time, revert to previous versions, and work on different branches without affecting the main code.

2.  **Collaboration:** Multiple people can work on the same project simultaneously, and Git provides powerful tools to merge changes and resolve conflicts.

**Weaknesses:**

1.  **Steep Learning Curve:** Beginners can find Git difficult to learn, especially when dealing with merge conflicts or using advanced commands.

2.  **Complex History:** For larger projects, the commit history can become messy and hard to understand if not managed properly.

## Exercise 2: Putting your Repository on GitHub

Here is the link to the repository: [GitHub Repository](https://github.com/leakunze2606/exeRcise-sheet-3)

## Exercise 3: Pixar Films

### a)

```{r}
library(tidyverse)

pixar <- read_csv("pixar_films.csv") %>%
  filter(!is.na(film))

unique(pixar$film_rating)

pixar <- pixar %>%
  mutate(film_rating = factor(film_rating))
```

The variable `film_rating` contains values based on the Motion Picture Association (MPA) film rating system. It describes how films are rated for content suitability.

By inspecting the dataset, we can see that the possible values for `film_rating` are labels such as `"G"`, `"PG"`, `"PG-13"`, or `"NR"`. These represent different rating categories from the MPA system, but the dataset itself does not define the exact meanings. It only tells us that the ratings follow the MPA standard.

Creating a **factor variable** for `film_rating` is appropriate because the ratings represent a fixed set of **categorical values**. Factors are useful for modeling and plotting categorical data and help ensure that R treats the values as discrete levels instead of free-form text.

### b)

```{r}
library(dplyr)
library(stringr)
# Manually film titles
movies <- data.frame(
  reihe = c(
    "A Bug's Life", "Brave", "Cars", "Cars 2", "Cars 3", "Coco", "Finding Dory", "Finding Nemo", "Incredibles 2", "Inside Out", "Lightyear", "Luca", "Monsters University", "Monsters, Inc.", "Onward", "Ratatouille", "The Good Dinosaur", "The Incredibles", "Toy Story", "Toy Story 2", "Toy Story 3", "Toy Story 4", "Turning Red", "Up", "WALL-E" 
    ),
  stringsAsFactors = FALSE
)

movies$series <- c(
  "Standalone", "Standalone", "Cars", "Cars", "Cars", "Standalone", "Finding Nemo", "Finding Nemo",
  "The Incredibles", "Standalone", "Standalone", "Standalone", "Monsters, Inc.", "Monsters, Inc.",
  "Standalone", "Standalone", "Standalone", "The Incredibles", "Toy Story", "Toy Story", 
  "Toy Story", "Toy Story", "Standalone", "Standalone", "Standalone"
)

# Groub by series and summarize
library(dplyr)

series_summary <- movies %>%
  group_by(series) %>%
  summarise(
    titles = paste(reihe, collapse = ", "),
    count = n()
  ) %>%
  ungroup()

print(series_summary)

```

### c)

```{r}
# load data
public_response <- read.csv("public_response.csv")

levels_order <- sort(unique(public_response$cinema_score))
public_response$cinema_score <- factor(public_response$cinema_score, levels = levels_order, ordered = TRUE)
# merge 
combined_data <- merge(public_response, pixar, by = "film")
```

### d)

```{r}
library(ggplot2)
library(dplyr)

# numeric
combined_data$release_date <- as.Date(combined_data$release_date)  # oder numeric Jahr

# sort 
combined_data <- combined_data %>%
  arrange(release_date) %>%
  mutate(film = factor(film, levels = unique(film)))

# Plot
ggplot(combined_data, aes(x = film, y = metacritic, fill = film)) +
  geom_bar(stat = "identity") +
  labs(title = "Metacritic Scores Movies (sorted by date)",
       x = "Film",
       y = "Metacritic Score") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none")
```

I noticed that the *Cars* movies were rated increasingly worse over time. Generally, the later installments in a film series tend to receive lower ratings. According to the data, *Ratatouille* was the best received by the public.

## Exercise 4: Open Analysis

### a) For this analysis, I selected the following dataset:

-   **Title:** *German road deaths and accidents*\
-   **Source:** [Link to dataset](https://github.com/owid/owid-datasets/tree/master/datasets/German%20road%20deaths%20and%20accidents%20-%20destatis)

The dataset contains information about traffic accidents and road deaths in Germany over several years.

### b) / c) Data Import and Git Tracking

```{r}
library(readr)
German_road_deaths_and_accidents_destatis <- read_csv("German road deaths and accidents - destatis.csv")
```

The dataset was downloaded into my project folder and tracked using Git.

### d) Research Question: How did the proportion of fatal road accidents change over time between 1960 and 2016?

**Why is this interesting?**

This question is interesting because it investigates whether, despite an increase in the number of accidents (e.g., due to more traffic), the severity of accidents is increasing or decreasing. For example, if the fatality rate per accident is decreasing, this could indicate improvements such as better road infrastructure, safer vehicles, or enhanced medical care.

The **Fatality Rate** is a measure that shows how severe road accidents are by indicating the proportion of accidents that result in deaths. It is calculated as: $$
\text{Fatality Rate} = \frac{\text{Number of Road Deaths}}{\text{Number of Accidents Reported to Police}}
$$

### e) Data Analysis

```{r}
# clean data with janitor
library(janitor)
German_road_deaths_and_accidents_destatis <- 
  clean_names(German_road_deaths_and_accidents_destatis)
# new variable "Fatality Rate"
German_road_deaths_and_accidents_destatis$fatality_rate <- 
  German_road_deaths_and_accidents_destatis$road_deaths / 
  German_road_deaths_and_accidents_destatis$accidents_reported_to_police

#linear regression
model <- lm(fatality_rate ~ year, data = German_road_deaths_and_accidents_destatis)
summary(model)


```

**Results:**

-   The intercept ( 𝛽 0 β 0 ​ ) is approximately 0.6671, which represents the estimated fatality rate when the year is zero (this is outside the range of our data, so it mainly serves as a model baseline).

-   The coefficient for year ( 𝛽 1 β 1 ​ ) is approximately -0.0003319. This indicates that the fatality rate decreases by about 0.00033 (or 0.033%) per year on average.

-   The p-value for the year coefficient is \< 2e-16, showing that this decreasing trend is highly statistically significant.

-   The model explains approximately 90.6% of the variance in fatality rate ( 𝑅 2 = 0.906 R 2 =0.906), which indicates an excellent fit.

**Interpretation:** There is a clear and significant downward trend in the fatality rate over time. Each passing year corresponds to a small but consistent reduction in fatality rate, suggesting improvements in road safety or related factors.

### f) Visualization

```{r fatality-rate-plot, fig.cap="Figure 1: Fatality Rate in Germany from 1960 to 2016. Each point represents one year. The red line shows the linear trend."}
# Filter for years 1960–2016
data_filtered <- subset(German_road_deaths_and_accidents_destatis, year >= 1960 & year <= 2016)

# Plot each year's fatality rate
plot(data_filtered$year, data_filtered$fatality_rate,
     type = "p",          
     col = "blue",
     pch = 19,           
     xlab = "Year",
     ylab = "Fatality Rate",
     main = "Fatality Rate in Germany, Road (1960–2016)",
     xaxt = "n",
     ylim = c(min(data_filtered$fatality_rate), max(data_filtered$fatality_rate))
)

# Add every year label on x-axis
axis(1, at = data_filtered$year, las = 2, cex.axis = 0.7)

# Add linear regression line
model <- lm(fatality_rate ~ year, data = data_filtered)
abline(model, col = "red", lwd = 2)
```
